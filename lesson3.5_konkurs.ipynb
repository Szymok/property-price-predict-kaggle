{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](../images/dummy_benchmark.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "import scikitplot as skplt\n",
    "from scikitplot.estimators import plot_learning_curve\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "\n",
    "from functools import partial\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "train = pd.read_hdf('../input/property.train.h5')\n",
    "test = pd.read_hdf('../input/property.test.h5')\n",
    "\n",
    "df_all = pd.concat([train, test], sort=False)\n",
    "# Reduce street names\n",
    "def filter_string(s):\n",
    "    if s != np.nan:\n",
    "        s = str(s)\n",
    "        return re.sub(r'^.*?\\.|ул', '', s).strip()\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "# Clean geo block column\n",
    "def clean_bread_geo(l):\n",
    "    new_l = []\n",
    "    for i in l:\n",
    "        new_l.append(filter_string(i))\n",
    "    new_l = list(dict.fromkeys(new_l))\n",
    "    return new_l\n",
    "\n",
    "# Keep only unique from breadcrumbs\n",
    "def strib_bread_from_geo(r):\n",
    "    r['breadcrumbs_clean'] = tuple([x for x in r['breadcrumbs_clean'] if x not in r['geo_block_clean']])\n",
    "    return r\n",
    "\n",
    "# Get subway\n",
    "def get_mlik(l):\n",
    "    for i in l:\n",
    "        new_l = i.split()\n",
    "        if 'МЦК' in new_l:\n",
    "            return i\n",
    "    return np.nan\n",
    "\n",
    "# Remove subway from breadcrumbs\n",
    "def remove_mlik(l):\n",
    "    blacklist = ['МЦК']\n",
    "    vals_to_rem = []\n",
    "    for i in l:\n",
    "        new_l = i.split()\n",
    "        for j in new_l:\n",
    "            if j in blacklist:\n",
    "                vals_to_rem.append(i)\n",
    "                break\n",
    "    return [x for x in l if x not in vals_to_rem]\n",
    "\n",
    "# Extract year from date\n",
    "def get_year(l):\n",
    "    date = l[0].split()\n",
    "    for x in date:\n",
    "        if x in ('2014', '2015', '2016', '2017', '2018', '2013'):\n",
    "            return x\n",
    "    return np.nan\n",
    "\n",
    "     \n",
    "def is_new_moscow(l):\n",
    "    return 'yes' if 'Новая Москва' in l else np.nan\n",
    "\n",
    "# Get security features from security\n",
    "def get_from_security(x, word):\n",
    "    split_x = x.replace('x,', ' ').split()\n",
    "    for i in split_x:\n",
    "        if i.lower() in word:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Append kitchen furniture\n",
    "def get_kitchen(r):\n",
    "    l = []\n",
    "    if r['Fridge:'] == 'yes':\n",
    "        l.append('fridge')\n",
    "    if r['Kitchen furniture:'] == 'yes':\n",
    "        l.append('furniture')\n",
    "    r['Kitchen furniture:'] = tuple(l)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['breadcrumbs_clean'] = df_all['breadcrumbs'].map(clean_bread_geo)\n",
    "df_all['geo_block_clean'] = df_all['geo_block'].map(lambda x: tuple(clean_bread_geo(x)))\n",
    "df_all['breadcrumbs_clean'] = df_all['breadcrumbs_clean'].map(remove_mlik)\n",
    "df_all = df_all.apply(strip_bread_grom_geo, axis=1)\n",
    "df_all['subway'] = df_all['breadcrumbs'].map(get_mlik)\n",
    "df_all['date_clean'] = df_all.date.map(get_year)\n",
    "df_all['owner_clean'] = df_all.owner.map(lambda x: ''.join(x) if x else str(-1))\n",
    "df_all['new_moscow'] = df_all['geo_block_clean'].map(is_new_moscow)\n",
    "df_all['parking'] = df_all['Security:'].map(lambda x: 'yes' if get_from_security(str(x), ['parking']) == True else np.nan)\n",
    "df_all = df_all.apply(get_kitchen, axis=1)\n",
    "df_all['Construction phase:'] = np.where(df_all['Construction phase:'] == 'Playground', 'Finish', df_all['Construction_phase:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find security feats for given keywords\n",
    "potentail_sec = ['yes', 'provided', 'is', 'barrier', 'fenced', 'closed', 'area', 'territory', 'protected', 'access', 'allowed',\n",
    "                'alarm', 'fire', 'system', 'intercom', 'ip-intercom', 'concierge', 'video', 'surveillance', 'cctv', 'cameras', 'camera',\n",
    "                'security', 'guarded', 'round-the-clock', '24-hour']\n",
    "df_all['has_securiy'] = df_all['Security:'].map(lambda x: 'yes' if get_from_security(str(x), potentail_sec) == True else np.nan)\n",
    "df_all['concierge'] = df_all['Security:'].map(lambda x : 'yes' if get_from_security(str(x), ['concierge']) == True else np.nan)\n",
    "guards_l = ['security', 'guarded', 'round-the-clock', '24-hour']\n",
    "df_all['guards'] = df_all['Security:'].map(lambda x : 'yes' if get_from_security(str(x), guards_l) == True else np.nan)\n",
    "cctv_l = ['video', 'surveillance', 'cctv', 'cameras', 'camera']\n",
    "df_all['cctv'] = df_all['Security:'].map(lambda x : 'yes' if get_from_security(str(x), cctv_l) == True else np.nan)\n",
    "fence_l = ['barrier', 'fenced', 'closed', 'area', 'territory', 'protected']\n",
    "df_all['fenced'] = df_all['Security:'].map(lambda x : 'yes' if get_from_security(str(x), fence_l) == True else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean price for all given streets and then marks that street as expensive\n",
    "# if the street's mean price is greater than the mean price of all streets\n",
    "street_dict= {}\n",
    "df_all['price'] = np.where(df_all['price'].isnull(), -1, df_all['price'])\n",
    "def get_street(r):\n",
    "    for x in r['geo_block_clean']:\n",
    "        if x not in ['Новая Москва', 'Москва']:\n",
    "            if x in street_dict:\n",
    "                street_dict[x].append(r['price'])\n",
    "            else:\n",
    "                street_dict[x] = [r['price']]\n",
    "                \n",
    "df_all.apply(get_street, axis=1);\n",
    "\n",
    "nan_vals = {}\n",
    "for key, value in street_dict.items():\n",
    "    l = list(filter(lambda x: x != -1, value))\n",
    "    if l:\n",
    "        nan_vals[key] = np.mean(l)\n",
    "        \n",
    "df_all['price'] = np.where(df_all['price'] == -1, np.nan, df_all['price'])\n",
    "df_all['mean'] = df_all['price'].map(lambda x: -1)\n",
    "def set_mean(r):\n",
    "    for x in r['geo_block_clean']:\n",
    "        if x in nan_vals:\n",
    "            if nan_vals[x] > 11:\n",
    "                r['mean'] = 'yes'\n",
    "    return r\n",
    "df_all = df_all.apply(sen_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = df_all.select_dtypes(include=[object]).columns\n",
    "delete_values = ['breadcrumbs', 'date', 'geo_block', 'owner']\n",
    "for x in delete_values:\n",
    "    cat_feats = np.delete(cat_feats, np.where(cat_feats ==x))\n",
    "    \n",
    "for cat_feat in cat_feats:\n",
    "    df_all['{0}_cat'.format(cat_feat.lower()).replace(':', '').replace(' ', '_')] = pd.factorize(df_all[cat_feat], na_sentinel=-1)[0]\n",
    "    \n",
    "train = df_all[df_all['price'].notnull()]\n",
    "test = df_all[df_all['price'].isnull()]\n",
    "\n",
    "test1 = pd.read_hdf('../input/property.test.h5')\n",
    "test['id'] = test1['id']\n",
    "\n",
    "del df_all, test1\n",
    "gc.collect()\n",
    "del test['price']\n",
    "train.drop([41594, 27304], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_rem = [\n",
    "    'id',\n",
    "    'price',\n",
    "    'fridge_cat',\n",
    "    #'concierge_cat',\n",
    "    #'cctv_cat',\n",
    "    #'has_security_cat',\n",
    "    #'guards_cat',\n",
    "    #'fenced_cat',\n",
    "    #'security_cat',\n",
    "    #'washing_machine_cat'\n",
    "]\n",
    "\n",
    "feats = train.select_dtypes(include=[int]).columns.values\n",
    "for x in feats_rem:\n",
    "    feats = np.delete(feats, np.where(feats == x))\n",
    "    \n",
    "X = train[feats].values\n",
    "y = train['price'].values\n",
    "\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_approx_obj(y_true, y_pred):\n",
    "    z = y_pred - y_true\n",
    "    delta = 1.35\n",
    "    scale = 1.3 + (z/delta)**2\n",
    "    scale_sqrt = np.sqrt(scale)\n",
    "    grad = z/scale_sqrt\n",
    "    hess = 10.3/(scale*scale_sqrt)\n",
    "    return grad, hess\n",
    "\n",
    "xgb_params = {\n",
    "        'max_depth': 8,\n",
    "        'colsample_bytree': 0.8021935159972803,\n",
    "        'learning_rate': 0.0859245491522357,\n",
    "        'subsample': 0.8973229799732887,\n",
    "       'random_state': 6700,\n",
    "        'min_child_weight': 2.0,\n",
    "        'reg_alpha': 1.3799196091897554,\n",
    "        'reg_lambda': 0.9862968829200137,\n",
    "        'n_estimators': 500,\n",
    "        'gamma' : 0.1,\n",
    "        'objective': huber_approx_obj,\n",
    "        'eval_metric': 'mae'    \n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred<0, -y_pred, y_pred)\n",
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_feature_importances(model, features):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('feature importances')\n",
    "    plt.bar(range(X.shape[1]), [features[x] for x in indices],\n",
    "           color='b', align='center')\n",
    "    plt.xticks(range(X.shape[1]), [features[x] for x in indices])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "draw_feature_importances(model, feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(20,10)\n",
    "sns.heatmap(train.corr(), vmax=1., vmin=-1., annot=True, linewidths=.8, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.estimators.plot_learning_curve(model, X, y, figsize=(15,5), cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "   \n",
    "    xgb_params = {\n",
    "        'max_depth': 17,\n",
    "        'colsample_bytree': 0.8021935159972803,\n",
    "        'learning_rate': 0.0859245491522357,\n",
    "        'subsample': 0.8868609961215616,\n",
    "        'random_state': 6700,\n",
    "        'min_child_weight': 2.0,\n",
    "        'reg_alpha': space['reg_alpha'],\n",
    "        'reg_lambda': space['reg_lambda'],\n",
    "        'n_estimators': 1700,\n",
    "        'objective': huber_approx_obj\n",
    "    }\n",
    "\n",
    "    print(space)\n",
    "    \n",
    "    model = xgb.XGBRegressor(**xgb_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = mean_absolute_error(y_test, y_pred)\n",
    "    print(score)\n",
    "    return {'loss':score, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    #'max_depth': hp.choice(\"max_depth\", np.arange(10,20,1)),\n",
    "    #'n_estimators':hp.quniform('n_estimators',300,2000,1),\n",
    "    #'colsample_bytree': hp.uniform ('x_colsample_bytree', 0.8, 1.),\n",
    "    #'learning_rate': hp.uniform ('x_learning_rate', 0.05, 0.2),\n",
    "    #'subsample': hp.uniform ('x_subsample', 0.7, 1.),\n",
    "    #'random_state': hp.quniform ('x_random_state', 0, 10000, 50),\n",
    "    #'min_child_weight': hp.quniform ('x_min_child_weight', 1, 10, 1),\n",
    "    'reg_alpha': hp.loguniform ('x_reg_alpha', 0., 1.2),\n",
    "    'reg_lambda': hp.uniform ('x_reg_lambda', 0.8, 1.),    \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective,\n",
    "                  space=space,\n",
    "                  algo=partial(tpe.suggest, n_startup_jobs=20),\n",
    "                  max_evals=50,\n",
    "                  trials=trials)\n",
    "\n",
    "print('The best params:', best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
